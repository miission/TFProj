{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "#### she changlue\n",
    "24th April 2017\n",
    "\n",
    "This project is use simple classification model to handle topic classification problems.This is a classical supervision learning problems which we manually label 2,000 samples to feed the logistic regression model. This edition will ignore the order of words(BOW) and use the TF-IDF to select the key words to as the features. \n",
    "\n",
    "this notebook will process as follow:\n",
    "1. load library and raw corpus data\n",
    "2. cut the corpus in to a list format(transfer the money term, number term and infrequence term into SPEC norm:MONE,NUMB,IFQT)\n",
    "3. compute the TF-IDF, and get the most import 100 tokens as the features\n",
    "4. construct the training and testing data sets\n",
    "5. training the logistic regression model\n",
    "6. evaluation the model results\n",
    "7. save the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)   load library and raw corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "from random import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression#linear classification model\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import jieba.posseg as pseg # cut the documents with token and tags\n",
    "import jieba\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### set hyper prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HYPA_featureNums = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('corpus/催收sample2.csv', header=0,encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corpus briefing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opr_rem</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>cls</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>今天下午5点472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t告知客户电话15226088432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>说是叔侄关系  转告</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>客户承诺今天下午五点存入184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    opr_rem  Unnamed: 1  cls  Unnamed: 3  \\\n",
       "0                                 今天下午5点472         NaN    4         NaN   \n",
       "1                       \\t告知客户电话15226088432         NaN    3         NaN   \n",
       "2                               说是叔侄关系  转告          NaN    3         NaN   \n",
       "3                           客户承诺今天下午五点存入184         NaN    4         NaN   \n",
       "4  已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决         NaN    4         NaN   \n",
       "\n",
       "   Unnamed: 4  Unnamed: 5 Unnamed: 6  \n",
       "0         NaN         NaN        NaN  \n",
       "1         NaN         NaN        NaN  \n",
       "2         NaN         NaN        NaN  \n",
       "3         NaN         NaN        NaN  \n",
       "4         NaN         NaN        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>cls</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.115731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.149538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.160247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 1          cls  Unnamed: 3  Unnamed: 4  Unnamed: 5\n",
       "count         0.0  1996.000000         0.0         0.0    7.000000\n",
       "mean          NaN     4.115731         NaN         NaN    4.000000\n",
       "std           NaN     1.149538         NaN         NaN    2.160247\n",
       "min           NaN     1.000000         NaN         NaN    1.000000\n",
       "25%           NaN     4.000000         NaN         NaN         NaN\n",
       "50%           NaN     4.000000         NaN         NaN         NaN\n",
       "75%           NaN     4.000000         NaN         NaN         NaN\n",
       "max           NaN     7.000000         NaN         NaN    7.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) cut the corpus in to a list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenCorpus  = []#corpus list of cutted tokens\n",
    "rawSentences = []#raw text \n",
    "labels       = []#training labels\n",
    "#documents    = list(rawdata[rawdata['消息目标']=='机器人']['消息内容'])#text which is send by custormers\n",
    "documents    = list(rawdata['opr_rem'])#text which is send by custormers\n",
    "LABELS       = list(rawdata['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\changlue.she\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.108 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# cstruct the corpus\n",
    "for idx,sentence in enumerate(documents):\n",
    "    if len(str(sentence))>4:\n",
    "        sentence = sentence.replace('\\t','')\n",
    "        tokens = []    \n",
    "        for pair in pseg.lcut(sentence):\n",
    "            if pair.flag in ['t','n','ns','vs','nv','v']:\n",
    "                tokens.append(pair.word)\n",
    "            elif pair.flag=='m':\n",
    "                if len(str(pair.word))==11:\n",
    "                    tokens.append('NUMB')\n",
    "                else:\n",
    "                    tokens.append('MONE')   \n",
    "        if len(tokens)>1:\n",
    "            tokenCorpus.append(tokens)\n",
    "            rawSentences.append(sentence)\n",
    "            labels.append(LABELS[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['MONE', 'MONE', 'MONE'],\n",
       "  ['告知', '客户', '电话', 'NUMB'],\n",
       "  ['说', '是', '叔侄', '关系', '转告']],\n",
       " [4, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenCorpus[:3],labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['今天下午5点472',\n",
       "  '告知客户电话15226088432',\n",
       "  '说是叔侄关系  转告 ',\n",
       "  '客户承诺今天下午五点存入184',\n",
       "  '已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决'],\n",
       " [4, 3, 3, 4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawSentences[:5],labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) compute the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_term  = []   #the token frequency relate terms\n",
    "IDF_term = []   #the inverse document frequency relate terms\n",
    "ALL_term = []   #the all token frequency relate terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### put tokens into the containments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tokens in tokenCorpus:\n",
    "    tf = dict(Counter(tokens))\n",
    "    TF_term.append(tf)\n",
    "    IDF_term+=tf.keys()\n",
    "    ALL_term+=tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### compute the tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordFreq  = dict(Counter(ALL_term))\n",
    "allDocNum = len(TF_term)\n",
    "IDF       = dict(Counter(IDF_term))\n",
    "TF_IDF    = dict() \n",
    "for tf in TF_term:\n",
    "    for word in tf.keys():\n",
    "        TF_IDF.setdefault(word,0)\n",
    "        TF_IDF[word]+=tf[word]*np.log(allDocNum/IDF[word]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### get 100 most import tokens as the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxs = np.argsort(-np.array(list(TF_IDF.values())))[:HYPA_featureNums]\n",
    "features = [list(TF_IDF.keys())[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) construct the training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featMat = np.array([[1  if feature in tokens else 0 for feature in features ] for tokens in tokenCorpus])\n",
    "labels  = np.array(labels) \n",
    "samp_idx= np.arange(len(featMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(samp_idx)\n",
    "trainNum = int(0.7*len(samp_idx))\n",
    "trainIdx = samp_idx[:trainNum]\n",
    "testIdx  = samp_idx[trainNum:]\n",
    "trainX   = featMat[trainIdx]\n",
    "trainy   = labels[trainIdx]\n",
    "testX    = featMat[testIdx]\n",
    "testy    = labels[testIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5）training the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpara = [1,10,100,1000,0.1,0.01,0.001,0.0001,2,3,4,0.5,0.2,0.3,0.4,0.6,0.7,0.8,0.9]\n",
    "petype =['l1','l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803230543319 0.799657534247 |para:[c] 1 [penalty] l1\n"
     ]
    }
   ],
   "source": [
    "bstScore = 0\n",
    "for pty in petype:\n",
    "    for cp in cpara:\n",
    "        clf = LogisticRegression(C=cp,penalty=pty)\n",
    "        clf.fit(trainX,trainy)\n",
    "        teScore = clf.score(testX,testy)\n",
    "        if teScore>bstScore:\n",
    "            bstScore = teScore\n",
    "            print(clf.score(trainX,trainy),teScore,'|para:[c]',cp,'[penalty]',pty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
